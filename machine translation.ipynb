{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"machine translation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1r_S6zTJAvWN5J43qnyLQx8H79zkjyTgM","authorship_tag":"ABX9TyO0ox65iHGECkeInmLQASGb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"P-fvH2MdHWSl"},"source":["https://colab.research.google.com/drive/1uFJBO1pgsiFwCGIJwZlhUzaJ2srDbtw-#scrollTo=Fesymsn34v7z"]},{"cell_type":"markdown","metadata":{"id":"OZvQLQFOlCJc"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"id":"kQ67XPEOk3G8"},"source":["import torchvision\n","import torch \n","import torch.nn as nn \n","import torch.functional as F \n","import torch.optim as optim\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjYwOKUVlHSJ"},"source":["import pandas as pd \n","from sklearn.model_selection import train_test_split\n","import numpy as np \n","import unicodedata\n","import re \n","import time \n","import os "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"dj0uOkfrl6qh","executionInfo":{"status":"ok","timestamp":1634370786479,"user_tz":-420,"elapsed":33,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"6814b906-4b01-4db8-d5bf-8ab5af14ac8b"},"source":["torch.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.9.0+cu111'"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwBXSj1BtXjw","executionInfo":{"status":"ok","timestamp":1634370786480,"user_tz":-420,"elapsed":29,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"47f4bb07-ddb7-45ac-9668-9faab8e7a888"},"source":["cd drive/MyDrive/Colab\\ Notebooks/Daily_Coding/Seq2seq+attention"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/Daily_Coding/Seq2seq+attention'\n","/content/drive/MyDrive/Colab Notebooks/Daily_Coding/Seq2seq+attention\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFD8VnpCuJX4","executionInfo":{"status":"ok","timestamp":1634370786938,"user_tz":-420,"elapsed":470,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"34f734eb-b102-423f-ab47-d34cb6ef6255"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" \u001b[0m\u001b[01;34mdata\u001b[0m/  'machine translation.ipynb'   Seq2seq+attention.ipynb\n"]}]},{"cell_type":"code","metadata":{"id":"OPrGvmLNl8Ai","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634370786939,"user_tz":-420,"elapsed":7,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"50c28603-d922-4106-f80e-6630d2dae105"},"source":["ls data/train-en-vi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train.en  train.vi\n"]}]},{"cell_type":"markdown","metadata":{"id":"Mg5LitpVpqPE"},"source":["# Prepare dataset"]},{"cell_type":"code","metadata":{"id":"4-r-UGj2nxoG"},"source":["DATA_PATH = \"./data/\"\n","TRAIN_SRC_PATH = os.path.join(DATA_PATH, \"train-en-vi/train.en\")\n","TRAIN_TGT_PATH = os.path.join(DATA_PATH, \"train-en-vi/train.vi\")\n","DEV_SRC_PATH = os.path.join(DATA_PATH, \"dev-en-vi/tst2012.en\")\n","DEV_TGT_PATH = os.path.join(DATA_PATH, \"dev-en-vi/tst2012.vi\")\n","TEST_SRC_PATH = os.path.join(DATA_PATH, \"test-en-vi/tst2013.en\")\n","TEST_TGT_PATH = os.path.join(DATA_PATH, \"test-en-vi/tst2013.vi\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"32iqNUlYouNJ"},"source":["train_src_sentences = open(TRAIN_SRC_PATH, \"r\").read().split(\"\\n\")\n","train_tgt_sentences = open(TRAIN_TGT_PATH, \"r\").read().split(\"\\n\")\n","dev_src_sentences = open(DEV_SRC_PATH, \"r\").read().split(\"\\n\")\n","dev_tgt_sentences = open(DEV_TGT_PATH, \"r\").read().split(\"\\n\")\n","test_src_sentences = open(TEST_SRC_PATH, \"r\").read().split(\"\\n\")\n","test_tgt_sentences = open(TEST_TGT_PATH, \"r\").read().split(\"\\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"kITeghoZo13V","executionInfo":{"status":"ok","timestamp":1634370787347,"user_tz":-420,"elapsed":31,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"98fa4adb-7d33-44e6-e637-8558086b270d"},"source":["train_sentences = pd.DataFrame(train_src_sentences, columns=[\"eng\"])\n","train_sentences[\"vi\"] = train_tgt_sentences\n","train_sentences.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>vi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Rachel Pike : The science behind a climate hea...</td>\n","      <td>Khoa học đằng sau một tiêu đề về khí hậu</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>In 4 minutes , atmospheric chemist Rachel Pike...</td>\n","      <td>Trong 4 phút , chuyên gia hoá học khí quyển Ra...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I &amp;apos;d like to talk to you today about the ...</td>\n","      <td>Tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Headlines that look like this when they have t...</td>\n","      <td>Có những dòng trông như thế này khi bàn về biế...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>They are both two branches of the same field o...</td>\n","      <td>Cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 eng                                                 vi\n","0  Rachel Pike : The science behind a climate hea...           Khoa học đằng sau một tiêu đề về khí hậu\n","1  In 4 minutes , atmospheric chemist Rachel Pike...  Trong 4 phút , chuyên gia hoá học khí quyển Ra...\n","2  I &apos;d like to talk to you today about the ...  Tôi muốn cho các bạn biết về sự to lớn của nhữ...\n","3  Headlines that look like this when they have t...  Có những dòng trông như thế này khi bàn về biế...\n","4  They are both two branches of the same field o...  Cả hai đều là một nhánh của cùng một lĩnh vực ..."]},"metadata":{},"execution_count":87}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"xWy0pGedpXjI","executionInfo":{"status":"ok","timestamp":1634370787348,"user_tz":-420,"elapsed":26,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"7a6e0837-571f-46b2-c064-482401516229"},"source":["dev_sentences = pd.DataFrame(dev_src_sentences, columns=[\"eng\"])\n","dev_sentences[\"vi\"] = dev_tgt_sentences\n","dev_sentences.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>vi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>How can I speak in 10 minutes about the bonds ...</td>\n","      <td>Làm sao tôi có thể trình bày trong 10 phút về ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>This is not a finished story .</td>\n","      <td>Câu chuyện này chưa kết thúc .</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>It is a jigsaw puzzle still being put together .</td>\n","      <td>Nó là một trò chơi ghép hình vẫn đang được xếp .</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Let me tell you about some of the pieces .</td>\n","      <td>Hãy để tôi kể cho các bạn về vài mảnh ghép nhé .</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Imagine the first piece : a man burning his li...</td>\n","      <td>Hãy tưởng tượng mảnh đầu tiên : một người đàn ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 eng                                                 vi\n","0  How can I speak in 10 minutes about the bonds ...  Làm sao tôi có thể trình bày trong 10 phút về ...\n","1                     This is not a finished story .                     Câu chuyện này chưa kết thúc .\n","2   It is a jigsaw puzzle still being put together .   Nó là một trò chơi ghép hình vẫn đang được xếp .\n","3         Let me tell you about some of the pieces .   Hãy để tôi kể cho các bạn về vài mảnh ghép nhé .\n","4  Imagine the first piece : a man burning his li...  Hãy tưởng tượng mảnh đầu tiên : một người đàn ..."]},"metadata":{},"execution_count":88}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"DypHmrJpp3gM","executionInfo":{"status":"ok","timestamp":1634370787349,"user_tz":-420,"elapsed":24,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"40155588-19a8-4ad6-cd63-196e71095ac6"},"source":["test_sentences = pd.DataFrame(test_src_sentences, columns=[\"eng\"])\n","test_sentences[\"vi\"] = test_tgt_sentences\n","test_sentences.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>vi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>When I was little , I thought my country was t...</td>\n","      <td>Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>And I was very proud .</td>\n","      <td>Tôi đã rất tự hào về đất nước tôi .</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>In school , we spent a lot of time studying th...</td>\n","      <td>Ở trường , chúng tôi dành rất nhiều thời gian ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Although I often wondered about the outside wo...</td>\n","      <td>Mặc dù tôi đã từng tự hỏi không biết thế giới ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>When I was seven years old , I saw my first pu...</td>\n","      <td>Khi tôi lên 7 , tôi chứng kiến cảnh người ta x...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 eng                                                 vi\n","0  When I was little , I thought my country was t...  Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên ...\n","1                             And I was very proud .                Tôi đã rất tự hào về đất nước tôi .\n","2  In school , we spent a lot of time studying th...  Ở trường , chúng tôi dành rất nhiều thời gian ...\n","3  Although I often wondered about the outside wo...  Mặc dù tôi đã từng tự hỏi không biết thế giới ...\n","4  When I was seven years old , I saw my first pu...  Khi tôi lên 7 , tôi chứng kiến cảnh người ta x..."]},"metadata":{},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"PokWa8swr4Y-"},"source":["def preprocess_sentence(w):\n","    return '<start> ' + w + ' <end>'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"zuM6z2qhrAqU","executionInfo":{"status":"ok","timestamp":1634370787783,"user_tz":-420,"elapsed":453,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"8712b696-3405-47bd-ca9a-81b0246a609b"},"source":["train_sentences[\"eng\"] = train_sentences[\"eng\"].apply(lambda w: preprocess_sentence(w))\n","train_sentences[\"vi\"] = train_sentences[\"vi\"].apply(lambda w: preprocess_sentence(w))\n","train_sentences.sample(10)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>vi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>75633</th>\n","      <td>&lt;start&gt; Now in a sense , when we think about t...</td>\n","      <td>&lt;start&gt; Nói cách khác , khi chúng ta nghĩ về ả...</td>\n","    </tr>\n","    <tr>\n","      <th>12887</th>\n","      <td>&lt;start&gt; So we have to keep an eye on that . &lt;end&gt;</td>\n","      <td>&lt;start&gt; Vì vậy , chúng tôi phải để mắt đến điề...</td>\n","    </tr>\n","    <tr>\n","      <th>81207</th>\n","      <td>&lt;start&gt; For example , these were state-of-the-...</td>\n","      <td>&lt;start&gt; Ví dụ , đây là những hệ thống vũ khí t...</td>\n","    </tr>\n","    <tr>\n","      <th>96218</th>\n","      <td>&lt;start&gt; You put them in a portfolio and you tr...</td>\n","      <td>&lt;start&gt; Bạn đặt chúng vào một cặp hồ sơ và cố ...</td>\n","    </tr>\n","    <tr>\n","      <th>33516</th>\n","      <td>&lt;start&gt; And the conclusion was it was tasks th...</td>\n","      <td>&lt;start&gt; Và kết luận là những yêu cầu có đe doạ...</td>\n","    </tr>\n","    <tr>\n","      <th>98182</th>\n","      <td>&lt;start&gt; Now , if I came up here , and I wish I...</td>\n","      <td>&lt;start&gt; Nếu tôi được đứng ở đây và tôi ước rằn...</td>\n","    </tr>\n","    <tr>\n","      <th>106471</th>\n","      <td>&lt;start&gt; If we look at biology , and many of yo...</td>\n","      <td>&lt;start&gt; Nếu chúng ta nhìn vào sinh học , và nh...</td>\n","    </tr>\n","    <tr>\n","      <th>12341</th>\n","      <td>&lt;start&gt; So , completely irrational , you would...</td>\n","      <td>&lt;start&gt; Vì thế , hoàn toàn vô lý bạn sẽ nghĩ v...</td>\n","    </tr>\n","    <tr>\n","      <th>41331</th>\n","      <td>&lt;start&gt; So this was interesting . &lt;end&gt;</td>\n","      <td>&lt;start&gt; Nên điều này rất thú vị . &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>46387</th>\n","      <td>&lt;start&gt; But as soon as the wolves arrived , ev...</td>\n","      <td>&lt;start&gt; Nhưng ngay sau khi những con sói đến ,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                      eng                                                 vi\n","75633   <start> Now in a sense , when we think about t...  <start> Nói cách khác , khi chúng ta nghĩ về ả...\n","12887   <start> So we have to keep an eye on that . <end>  <start> Vì vậy , chúng tôi phải để mắt đến điề...\n","81207   <start> For example , these were state-of-the-...  <start> Ví dụ , đây là những hệ thống vũ khí t...\n","96218   <start> You put them in a portfolio and you tr...  <start> Bạn đặt chúng vào một cặp hồ sơ và cố ...\n","33516   <start> And the conclusion was it was tasks th...  <start> Và kết luận là những yêu cầu có đe doạ...\n","98182   <start> Now , if I came up here , and I wish I...  <start> Nếu tôi được đứng ở đây và tôi ước rằn...\n","106471  <start> If we look at biology , and many of yo...  <start> Nếu chúng ta nhìn vào sinh học , và nh...\n","12341   <start> So , completely irrational , you would...  <start> Vì thế , hoàn toàn vô lý bạn sẽ nghĩ v...\n","41331             <start> So this was interesting . <end>            <start> Nên điều này rất thú vị . <end>\n","46387   <start> But as soon as the wolves arrived , ev...  <start> Nhưng ngay sau khi những con sói đến ,..."]},"metadata":{},"execution_count":91}]},{"cell_type":"markdown","metadata":{"id":"At_itdC_sI5I"},"source":["#Building Vocabulary Index\n","\n","class sau dùng để tạo  ra vocabulary index mapping input, output thành index trong câu:"]},{"cell_type":"code","metadata":{"id":"HpBfAFxEsGfh"},"source":["# this class create word--> index (eg: \"dad\":5)\n","# and index--> word (5-->\"dad\") for each language\n","\n","class LanguageIndex():\n","    def __init__(self, lang):\n","        self.lang = lang \n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.vocab = set()\n","\n","        self.create_index()\n","\n","    def create_index(self):\n","        for phrase in self.lang:\n","            #update with individual (rieng bieet) tokens\n","            self.vocab.update(phrase.split(' '))\n","\n","        #sort vocab\n","        self.vocab = sorted(self.vocab)\n","\n","        #add a padding token with index 0\n","        self.word2idx['<pad>'] = 0\n","        \n","        #word to index mapping\n","        for index, word in enumerate(self.vocab):\n","            self.word2idx[word] = index + 1 #plus 1 because add pad token\n","\n","        #index to word mapping:\n","        for word, index in self.word2idx.items():\n","            self.idx2word[index] = word\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FjBXT0CuD_G"},"source":["input_lang = LanguageIndex(train_sentences[\"eng\"].values.tolist())\n","target_lang = LanguageIndex(train_sentences[\"vi\"].values.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WDtuTTbwuf3Y"},"source":["input_tensor = [[input_lang.word2idx[token] for token in sent.split(' ')] for sent in train_sentences[\"eng\"].values.tolist()]\n","target_tensor = [[target_lang.word2idx[token] for token in sent.split(' ')] for sent in train_sentences[\"vi\"].values.tolist()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-IweOKIus-H","executionInfo":{"status":"ok","timestamp":1634370791412,"user_tz":-420,"elapsed":21,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"c1b87628-cdc0-4681-82ae-934e46cce899"},"source":["input_tensor[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1609, 13405, 12761, 1606, 16100, 45808, 20468, 17799, 23083, 32178, 1608]"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"J-5dqkAAvEbo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634370791412,"user_tz":-420,"elapsed":15,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"4df71531-db7e-40ef-98ba-e21a6ca22750"},"source":["target_tensor[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1714,\n"," 8047,\n"," 18633,\n"," 25276,\n"," 22178,\n"," 20214,\n"," 23141,\n"," 25301,\n"," 24219,\n"," 18965,\n"," 18596,\n"," 1713]"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"gm7Nd--_unfv"},"source":["def max_length(sents):\n","    return max(len(t) for t in sents)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YktOo53sv7yW"},"source":["count = 0\n","for i,t in enumerate(input_tensor):\n","    if len(t) > 300:\n","        count+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"caDbEpQIwppN","executionInfo":{"status":"ok","timestamp":1634370791415,"user_tz":-420,"elapsed":14,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"836b7ce9-58aa-47db-db44-968115da6926"},"source":["print(count)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["15\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Rsayruzu7Jq","executionInfo":{"status":"ok","timestamp":1634370791415,"user_tz":-420,"elapsed":11,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"ad8fafbe-09fe-4e5d-dd61-72e7116495ab"},"source":["max_input_len, max_output_len = max_length(input_tensor), max_length(target_tensor)\n","print(f'max length of input and target: {max_input_len} and {max_output_len}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["max length of input and target: 630 and 852\n"]}]},{"cell_type":"markdown","metadata":{"id":"-isUbwq7zQRm"},"source":["Ta thấy nếu để max_len = 630 hay 852 thì nó quá dài để traing, chỉ 1 lượng nhỏ data có len > 300 nên ta sẽ để default MAX_LEN = 300"]},{"cell_type":"code","metadata":{"id":"zbO2olUoxdWG"},"source":["# Max length dài quá nên chắc phải để 300 tính cho nhanh, vì hầu hết sentences có len <300\n","MAX_LEN = 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wujLqJY_MET1"},"source":["def pad_sequences(x, max_len):\n","    padded = np.zeros((max_len), dtype = np.int64)\n","    if len(x) > max_len:\n","        padded[:] = x[:max_len]\n","    else: \n","        padded[:len(x)] = x\n","\n","    return padded"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImfNdAmvNkN6"},"source":["input_tensor = [pad_sequences(x, MAX_LEN) for x in input_tensor]\n","target_tensor = [pad_sequences(x, MAX_LEN) for x in target_tensor]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ui_wHnZWNye-","executionInfo":{"status":"ok","timestamp":1634370797872,"user_tz":-420,"elapsed":498,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"69538fb1-a34e-42df-c5c4-c110c5f6c514"},"source":["torch.tensor(input_tensor).shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([133318, 300])"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kaqHNuT_RHp8","executionInfo":{"status":"ok","timestamp":1634370802097,"user_tz":-420,"elapsed":301,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"d04d033c-364d-466f-8461-b948d8c9d299"},"source":["torch.tensor(target_tensor).shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([133318, 300])"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","metadata":{"id":"Fi59rwtXxvqh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634370802098,"user_tz":-420,"elapsed":11,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"44ca0c77-6496-400b-8a92-cb505626d99b"},"source":["input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor,test_size = 0.2)\n","\n","print(len(input_tensor_train), len(input_tensor_val), len(target_tensor_train), len(target_tensor_val))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["106654 26664 106654 26664\n"]}]},{"cell_type":"markdown","metadata":{"id":"C-JclQPnHS7f"},"source":["# Load data into DataLoader for Batching\n","\n"]},{"cell_type":"code","metadata":{"id":"ck-EPQuZwxWa"},"source":["from torch.utils.data import Dataset, DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3dJOrrPHkGT"},"source":["# convert data to tensors, pass to DadaLoader \n","\n","class MyData(Dataset):\n","    def __init__(self, X,y):\n","        self.data = X \n","        self.target = y\n","        \n","        #length of sentence = len(tensor) - len(pad)\n","        self.length = [np.sum(1 - np.equal(x, 0)) for x in X]\n","\n","    def __getitem__(self,index):\n","        x = self.data[index]\n","        y = self.target[index]\n","        x_len = self.length[index]\n","        return x,y,x_len\n","\n","    def __len__(self):\n","        return len(self.data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXIpdZl9Lfe6"},"source":["train_dataset = MyData(input_tensor_train, target_tensor_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsdaKUArLjEK"},"source":["train_dataset.data[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J7h_p7kGJj3u"},"source":["# Parameters \n"]},{"cell_type":"code","metadata":{"id":"B05qwFBuJi0N"},"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 32 \n","N_BATCH = BUFFER_SIZE//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024 \n","vocab_input_size = len(input_lang.word2idx)\n","vocab_target_size = len(target_lang.word2idx)\n","\n","train_dataset = MyData(input_tensor_train, target_tensor_train)\n","val_dataset = MyData(input_tensor_val, target_tensor_val)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7VNuMZiKmjd"},"source":["# Encoder "]},{"cell_type":"markdown","metadata":{"id":"0pu7Y8qq8KtX"},"source":["`pack` sequences trong Pytorch là gì?\n","\n","* khi training RNN(LSTM or GRU) thì độ giàu của các câu trong batch khác nhau. \n","Ví dụ: nếu sequences với batch = 8 có size lần lượt là: `[4,6,8,5,4,3,7,8]` thì bạn sẽ phải padding tất các các câu để có độ dài = max_sent = 8. Khi đó cần 64 phép tính (8x8) nhưng trên thực tế thì chỉ cần 45 là đủ. Tuy nhiên nếu muốn sử dụng fancy RNN (e.g. biLSTM) thì nó sẽ trở nên tính toán hard hơn khi padding và sẽ thực hiện nhiều phép tính hơn mức cần thiết. \n","\n","* Vì thế Pytorch cho phép pack sequence, trong packed sequence 2 có tuple. 1 tuple chứ các elements của sequence. tuple còn lại chứa size of each sequence trong batch.\n","\n","Ref: https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch"]},{"cell_type":"code","metadata":{"id":"P5PVelXSKkLz"},"source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n","        super(Encoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.enc_units = enc_units \n","        self.vocab_size = vocab_size \n","        self.embedding_dim = embedding_dim \n","        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n","        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n","\n","    def forward(self,x, lens, device):\n","\n","        #x: max_length x batch \n","        x = self.embedding(x)\n","        # max_length x batch x embedding_dim\n","        x = pack_padded_sequence(x, lens) #unpad \n","\n","        self.hidden = self.initialize_hidden_state(device)\n","        # 1 x batch x embedding_dim\n","\n","        output, self.hidden = self.gru(x, self.hidden)\n","        # output.shape: max_length x batch x hidden_dim\n","        #self.hidden: 1 x batch x\n","        output, _ = pad_packed_sequence(output)\n","        # print(output.shape)\n","\n","        return output, self.hidden\n","\n","    def initialize_hidden_state(self, device):\n","        return torch.zeros((1,self.batch_size, self.enc_units)).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"glA0j3RJ30qX"},"source":["### sort batch function to be able to use with pad_packed_sequence\n","def sort_batch(X, y, lengths):\n","    lengths, indx = lengths.sort(dim=0, descending=True)\n","    X = X[indx]\n","    y = y[indx]\n","    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Io2aJeQT4tMZ"},"source":["## Test Encoder"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ymiONVgz4GzS","executionInfo":{"status":"ok","timestamp":1634370806534,"user_tz":-420,"elapsed":510,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"980cb16b-714e-4301-b349-a1a6172c917b"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","test_encoder = Encoder(vocab_input_size, embedding_dim, units, BATCH_SIZE).to(device)\n","\n","it = iter(train_loader)\n","x,y,x_len = next(it)\n","x,y,x_len = sort_batch(x,y,x_len)\n","\n","out_enc, hidden_enc = test_encoder(x.to(device), x_len, device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([56, 32, 1024])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60bE0hBd6tEO","executionInfo":{"status":"ok","timestamp":1634370806534,"user_tz":-420,"elapsed":36,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"19c43616-73ba-4868-e5a7-a85040e10c44"},"source":["out_enc.shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([56, 32, 1024])"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qN2C4nrF65j_","executionInfo":{"status":"ok","timestamp":1634370806535,"user_tz":-420,"elapsed":21,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"7def508f-b592-4718-bede-47893c364a31"},"source":["hidden_enc.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 32, 1024])"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6U7pOa_7GWg","executionInfo":{"status":"ok","timestamp":1634370806535,"user_tz":-420,"elapsed":16,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"d2d2428b-a418-49b7-da31-a795a45f2e11"},"source":["x_len"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([56, 42, 37, 37, 36, 35, 35, 33, 33, 31, 30, 27, 25, 25, 25, 24, 22, 22,\n","        19, 19, 15, 12, 12, 11, 11, 11, 11, 10,  9,  8,  5,  5])"]},"metadata":{},"execution_count":117}]},{"cell_type":"markdown","metadata":{"id":"5MjA9xyl-3HR"},"source":["# Decoder\n","\n","<img src = \"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\">\n","\n","<img src = \"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\">\n","\n","Step:\n","* score = FC(tanh(FC(EO) + FC(H)))\n","* attention_weights = softmax(score, axis = 1) #batch x max_length x 1\n","* context_vector = sum(attention_weight x output_enc, axis = 1)\n","* embedding_output = input decoder pass qua embedding layer\n","* merged vector = concat(embedding_output, context_vector) \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"dCS1tcT3-wiB"},"source":["class Decoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_size):\n","        super(Decoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.dec_units = dec_units\n","        self.enc_units = enc_units\n","        self.vocab_size = vocab_size\n","        self.embedding_dim = embedding_dim\n","        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n","        self.gru = nn.GRU(self.embedding_dim + self.enc_units, self.dec_units, batch_first= True)\n","        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n","\n","        #use for attention:\n","        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n","        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n","        self.V = nn.Linear(self.enc_units, 1)\n","\n","    def forward(self, x, hidden, enc_output):\n","\n","        #enc_out: max_len x batch x hidden_dim \n","        enc_output = enc_output.permute(1,0,2)\n","        #enc_out: batch x max_len x hidden_dim \n","\n","        #hidden : batch x hidden_dim --> permute: batch x 1 x hidden_dim \n","        hidden = hidden.permute(1,0,2)\n","\n","        #use bahanau equal we hat:\n","        score = self.V(torch.tanh(self.W1(enc_output) + self.W2(hidden)))\n","        # batch x max_len x 1\n","\n","        attention_weights = torch.softmax(score, dim = 1) \n","        #batch x max_len x 1 \n","\n","        #context vector:\n","        context_vector = torch.sum(attention_weights * enc_output, dim = 1)\n","        # (batch x max_len x 1) * (batch x max_len x hidden_dim) = batch x max_len x hidden_dim \n","        # sum--> batch x hidden_dim\n","        # print(f'shape of context vector is {context_vector.shape}')\n","        x = self.embedding(x)\n","        #batch x 1 x embedding_dim \n","        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n","        # x = batch x 1 x (enc_dim + dec_dim)\n","\n","        #pass qua GRU:\n","        output, state = self.gru(x)\n","        #output: batch x 1 x hidden_dim \n","        #state: batch x 1 x hidden_dim \n","\n","        output = output.view(-1, output.size(2))\n","        #batch x hidden_dim\n","\n","        x = self.fc(output)\n","\n","        return x, state, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cmGQicQsOXcM"},"source":["## Test Decoder"]},{"cell_type":"code","metadata":{"id":"ZpLHVODkHJuc"},"source":["test_decoder = Decoder(vocab_target_size, embedding_dim, units, units, BATCH_SIZE).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgnFDjYMLj1W"},"source":["hidden_dec = hidden_enc \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KOTUNJ_gLuG6"},"source":["input_dec = torch.tensor([[target_lang.word2idx['<start>']]] * BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6gcP2PFMGpc","executionInfo":{"status":"ok","timestamp":1634373127139,"user_tz":-420,"elapsed":9,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"e34e2bb7-fe61-4b6b-fd51-e0e4a3800e0c"},"source":["input_dec.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 1])"]},"metadata":{},"execution_count":165}]},{"cell_type":"code","metadata":{"id":"vNQR7O2kMHmT"},"source":["for t in range(1, y.size(1)):\n","    x,state, attn_weights = test_decoder(input_dec.to(device), \n","                                         hidden_dec.to(device), \n","                                         out_enc.to(device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CqGZzDkMxTc","executionInfo":{"status":"ok","timestamp":1634373129348,"user_tz":-420,"elapsed":17,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"ec169619-5dd4-4220-8e11-14c8e7c3508f"},"source":["hidden_dec.permute(1,0,2).shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 1, 1024])"]},"metadata":{},"execution_count":167}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ldUNViiNM5Z9","executionInfo":{"status":"ok","timestamp":1634373140091,"user_tz":-420,"elapsed":322,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"9bd7e151-188c-4348-e433-ffa374d500c1"},"source":["x.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 25619])"]},"metadata":{},"execution_count":168}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjznbxoCOvhZ","executionInfo":{"status":"ok","timestamp":1634373205524,"user_tz":-420,"elapsed":293,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"66d53070-b880-460e-e818-bf782aed3e17"},"source":["state.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 32, 1024])"]},"metadata":{},"execution_count":169}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9HB2YW8O_le","executionInfo":{"status":"ok","timestamp":1634373214529,"user_tz":-420,"elapsed":513,"user":{"displayName":"19020475 Phan Đình Đan Trường","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14474264519991938299"}},"outputId":"2e9e386d-506e-46f8-fc4e-60017ffbdb02"},"source":["attn_weights.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 56, 1])"]},"metadata":{},"execution_count":170}]},{"cell_type":"markdown","metadata":{"id":"YTKdmnuxPUmo"},"source":["# Define loss, hyperparameters..."]},{"cell_type":"code","metadata":{"id":"HPuQDFKHPBta"},"source":["criterion = nn.CrossEntropyLoss()\n","\n","def loss_function(real, pred):\n","    \"\"\"chỉ cần xem xét những giá trị khác o, những giá trị = 0 có thể mask đi\"\"\"\n","    # mask = real.ge(1).type(torch.cuda.FloatTensor)\n","    mask = 1 - np.equal(real, 0)\n","    loss = criterion(pred, real) * mask\n","    return torch.mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wTZpgIw0PzU_"},"source":["mask = 1 - np.equal(y, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeEAdyU6P0Bo"},"source":["mask[30]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6lSyZ13P9R3"},"source":["y[30]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uebXpNBmQbqF"},"source":["encoder = Encoder(vocab_input_size, embedding_dim, units, BATCH_SIZE)\n","decoder = Decoder(vocab_target_size, embedding_dim, units, units, BATCH_SIZE)\n","\n","encoder.to(device)\n","decoder.to(device)\n","\n","optimizer = optim.Adam(list(encoder.parameters())+ list(decoder.parameters()), lr = 0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mEWLX7U9Refi"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"NFKh83svRkeL"},"source":["from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Vse0NRYRa12"},"source":["EPOCHS = 10\n","\n","for epoch in tqdm(range(EPOCHS)):\n","    start = time.time()\n","\n","    encoder.train()\n","    decoder.train()\n","\n","    total_loss = 0\n","    \n","    for (batch_idx, (input, target, input_len)) in enumerate(train_loader):\n","        loss = 0\n","        x,y,x_len = sort_batch(input,target,input_len)\n","\n","        enc_output, enc_hidden = encoder(x.to(device), x_len, device)\n","        dec_hidden = enc_hidden\n","\n","        dec_input = torch.tensor([[target_lang.word2idx['<start>']]] * BATCH_SIZE)\n","\n","        for t in range(1, y.size(1)):\n","            pred, dec_hidden, _ = decoder(dec_input.to(device), \n","                                          dec_hidden.to(device),\n","                                          enc_output.to(device))\n","            \n","            loss+= loss_function(y[:,t].to('cpu'), pred.to('cpu'))\n","            dec_input = y[:,t].unsqueeze(1)\n","\n","        batch_loss = (loss/int(y.size(1)))\n","        total_loss += batch_loss\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        if batch_idx%100 == 0:\n","            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch_idx, batch_loss.detach().item()))\n","    \n","    #TODO: save checkpoint for model \n","    print('EPOCH {} LOSS {:.4f}'.format(epoch+1, total_loss/N_BATCH))\n","    print('Tine taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"644uOgPoTUYv"},"source":[""],"execution_count":null,"outputs":[]}]}